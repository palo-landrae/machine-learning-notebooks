{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run your first classifier with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the *Pima Indians Diabetes Database* dataset thorugh pandas.\n",
    "\n",
    "__Context__:\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. __The objective of the project is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset__. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "link to the [dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/diabetes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timespreg</th>\n",
       "      <th>gluctol</th>\n",
       "      <th>diaspb</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>massindex</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timespreg  gluctol  diaspb  triceps  insulin  massindex  pedigree  age  \\\n",
       "0            6      148      72       35        0       33.6     0.627   50   \n",
       "1            1       85      66       29        0       26.6     0.351   31   \n",
       "2            8      183      64        0        0       23.3     0.672   32   \n",
       "3            1       89      66       23       94       28.1     0.167   21   \n",
       "4            0      137      40       35      168       43.1     2.288   33   \n",
       "..         ...      ...     ...      ...      ...        ...       ...  ...   \n",
       "763         10      101      76       48      180       32.9     0.171   63   \n",
       "764          2      122      70       27        0       36.8     0.340   27   \n",
       "765          5      121      72       23      112       26.2     0.245   30   \n",
       "766          1      126      60        0        0       30.1     0.349   47   \n",
       "767          1       93      70       31        0       30.4     0.315   23   \n",
       "\n",
       "     target  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  \n",
       "..      ...  \n",
       "763       0  \n",
       "764       0  \n",
       "765       0  \n",
       "766       1  \n",
       "767       0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print class frequencies through pandas \n",
    "(Tenere presente che target = 1 vuol dire che il paziente ha il diabete, 0 che non lo ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    500\n",
      "1    268\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('target').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot for the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.countplot(x=\"target\", data=df)\n",
    "plt.title(\"Diabetes Dataset\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the dataframe into a numpy matrix (numpy is the python package for scientific computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 268, 0.0: 500})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = df.to_numpy()\n",
    "x=df[:,0:-1] # prendiamo tutti i dati tranne l'ultima colonna -> variabili indipendenti, osservazioni\n",
    "y=df[:,-1] # prendiamo solo l'ultima colonna -> variabile dipendente, target\n",
    "\n",
    "#Print class frequencies through collections counter\n",
    "import collections\n",
    "collections.Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
      "  5.000e+01]\n",
      " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]\n",
      " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
      "  3.000e+01]\n",
      " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
      "  2.600e+01]\n",
      " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
      "  2.900e+01]\n",
      " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
      "  5.300e+01]\n",
      " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
      "  5.400e+01]]\n",
      "y = [1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(x[:10])\n",
    "print(f'y = {y[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.     35.      0.     33.6     0.627  50.   ]\n",
      " [  1.     85.     66.     29.      0.     26.6     0.351  31.   ]\n",
      " [  8.    183.     64.      0.      0.     23.3     0.672  32.   ]\n",
      " [  1.     89.     66.     23.     94.     28.1     0.167  21.   ]\n",
      " [  0.    137.     40.     35.    168.     43.1     2.288  33.   ]\n",
      " [  5.    116.     74.      0.      0.     25.6     0.201  30.   ]\n",
      " [  3.     78.     50.     32.     88.     31.      0.248  26.   ]\n",
      " [ 10.    115.      0.      0.      0.     35.3     0.134  29.   ]\n",
      " [  2.    197.     70.     45.    543.     30.5     0.158  53.   ]\n",
      " [  8.    125.     96.      0.      0.      0.      0.232  54.   ]]\n",
      "y = [1. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "print(x[:10])\n",
    "print(f'y = {y[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/ libreria per il Machine Learning in Python\n",
    "\n",
    "# come per altri metodi di ML, dobbiamo prendere i nostri valori delle osservazioni e splittarle in due insiemi:\n",
    "# training set: è il sottoinsieme delle osservazioni che serve al nostro metodo per imparare\n",
    "# test set: è il sottoinsieme delle osservazioni che serve al nostro metodo per capire se ha imparato bene\n",
    "\n",
    "from sklearn.model_selection import train_test_split # suddivide le osservazioni nei due insiemi\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    test_size = 0.33, # by default is 75%-25%\n",
    "                                                    # shuffle is set True by default,\n",
    "                                                    stratify = y, # per mantenere le proporzioni che ci sono nei dati di partenza\n",
    "                                                    random_state = 123) # fix random seed for replicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((514, 8), (514,), (254, 8), (254,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.    123.     74.     40.     77.     34.1     0.269  28.   ]\n",
      " [  6.     80.     66.     30.      0.     26.2     0.313  41.   ]\n",
      " [ 10.     68.    106.     23.     49.     35.5     0.285  47.   ]\n",
      " [ 12.     84.     72.     31.      0.     29.7     0.297  46.   ]\n",
      " [  2.    106.     64.     35.    119.     30.5     1.4    34.   ]\n",
      " [  2.     92.     76.     20.      0.     24.2     1.698  28.   ]\n",
      " [  6.     85.     78.      0.      0.     31.2     0.382  42.   ]\n",
      " [  2.     81.     72.     15.     76.     30.1     0.547  25.   ]\n",
      " [  7.    133.     84.      0.      0.     40.2     0.696  37.   ]\n",
      " [  2.    108.     52.     26.     63.     32.5     0.318  22.   ]]\n",
      "y_train = [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10])\n",
    "print(f'y_train = {y_train[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci sono molti metodi per classificare un nuovo elemento. Per questa prima lezione scegliamo il Nearest Neighbors Classifier (K-NN), che classifica un elemento cercando di capire a quali altri elementi è più 'vicino'. Il metodo ha un solo paramentro, il numero K, che indica il nuemro di osservazioni già classificate di cui tenere conto per determinare la vicinanza del nuovo elemento. Vediamo il funzionamento analizzando l'immagine seguente: \n",
    "\n",
    "<img src=\"Images/K-NN.png\" width=\"900\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dati predetti dal metodo =                [0. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "dati reali presenti nel dataset di test = [1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# importiamo il metodo che vogliamo utilizzara (tra i tanti disponibili...)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3) # impostiamo l'unico parametro (il numero di vicini)\n",
    "\n",
    "# prima parte: dobbiamo fare in modo che il metodo impari dalle informazioni a disposizione\n",
    "# NB: notare che il metodo utilizza sia X_train che y_train, perché deve capire se sta predicendo correttamente\n",
    "neigh.fit(X_train, y_train) # \"alleniamo\" il metodo con i dati del training set\n",
    "\n",
    "# seconda parte: vediamo se il metodo ha imparato bene facendogli prevedere i risultati \n",
    "# NB: notare che c'è solo X perché le y devono essere previste dal metodo\n",
    "predict = neigh.predict(X_test) # proviamo a fare una previsione sui dati del test set\n",
    "\n",
    "# visualizziamo il risultato (solo i primi dieci pazienti)\n",
    "print(f'dati predetti dal metodo =                {predict[:10]}') # dati predetti dal metodo\n",
    "print(f'dati reali presenti nel dataset di test = {y_test[:10]}') # dati effettivi presenti nel test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo come ha funzionato il nostro metodo analizzando i primi 10 pazienti (ricordiamoci che 1 vuol dire che il paziente ha il diabete, 0 che non lo ha)<br>\n",
    "\n",
    "- veri positivi (true positive, __TP__): quattro pazienti (nn. 3, 5, 7 e 9) sono stati classificati come diabetici ed effettivamente lo erano\n",
    "- veri negativi (true negative, __TN__): tre pazienti (nn. 4, 6 e 8) sono stati classificati come __non__ diabetici ed effettivamente non lo erano\n",
    "- falsi negativi (false negative, __FN__): un pazienti (n. 1) è stato classificato come __non__ diabetico anche se lo era \n",
    "- falsi positivi (false positive, __FP__): due pazienti (nn. 2 e 10) sono stati classificati come diabetici anche se __non__ lo erano \n",
    "\n",
    "Ma esiste un modo più scientifico per capire se il nostro metodo predice correttamente? Vediamo di valutare il nostro metodo con la confusion matrix e gli indicatori ad essa collegati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per valutare il nostro metodo, visualizziamo prima la cosiddetta \"confusion matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be run only once, code for the installation of a new library\n",
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plots IMPORTS\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predict), cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo di capire il suo significato, riprendendo l'esempio precedente e tenendo presente che le __predicted label__ rappresentano le previsioni del metodo (1 il paziente è diabetico, 0 non lo è) mentre le __true label__ rappresentano i dati reali presenti nel dataset (1 il paziente è diabetico, 0 non lo è):\n",
    "\n",
    "- veri positivi (true positive, __TP__): 50 pazienti sono stati classificati come diabetici (predicted label = 1) ed effettivamente lo erano (true label = 1)\n",
    "- veri negativi (true negative, __TN__): 123 pazienti sono stati classificati come __non__ diabetici (predicted label = 0) ed effettivamente __non__ lo erano (true label = 0)\n",
    "- falsi negativi (false negative, __FN__): 39 pazienti sono stati classificati come __non__ diabetici (predicted label = 0)  anche se in realtà lo erano (true label = 1)\n",
    "- falsi positivi (false positive, __FP__): 42 pazienti sono stati classificati come diabetici (predicted label = 1) anche se in realtà __non__ lo erano (true label = 0)\n",
    "\n",
    "L'immagine seguente dovrebbe aiutare a capire meglio i vari TP, TN, FN, e FP:\n",
    "\n",
    "<img src=\"Images/cf explained.png\" width=\"700\" align=\"center\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta definito i TP, TN, FN ed FP, possiamo definire anche alcuni indicatori e utilizzarli per capire se il metodo classifica bene il fenomeno o no.\n",
    "\n",
    "__accuracy: the fraction of predictions our model got right__<br>\n",
    "\n",
    "è la percentuale di previsioni (classificazioni) corrette, sia per i casi positivi che per quelli negativi. Nel nostro caso rappresenta, in percentuale, quanti diabetici e non diabetici sono stati individuati (classificati) correttamente dal nostro metodo<br>\n",
    "Vediamo come si calcola:<br>\n",
    "\\begin{equation*}\n",
    "accuracy = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{50 + 123}{50 + 123 + 42 + 39} = 0,6873\n",
    "\\end{equation*}\n",
    "\n",
    "Questo dato vuol dire che il metodo ha trovato correttamente chi ha il diabete e chi non lo ha nel __68%__ dei casi.\n",
    "\n",
    "In genere è la prima metrica che viene osservata quando si valuta un classificatore. Tuttavia, quando i dati di test non sono bilanciati (quando cioè la maggior parte delle istanze appartengono a una delle classi TP, TN FP o FN) o si è più interessati alle prestazioni in una delle classi (ad esempio TP), l'accuratezza non riesce a dare un'idea dell'efficacia di un classificatore. Pensate per esempio al caso in cui si tratti di trovare i contagiati da Coronavirus in un insieme di persone. Supponiamo di avere un dataset con 1000 osservazioni. Sappiamo che in questo dataset ci sono 3 contagiati e 997 sani. Supponiamo di eseguire il nostro metodo e ottenere i seguenti risultati:\n",
    "\n",
    "TP (il metodo dice che la persona è contagiosa ed effettivamente lo è): 0\n",
    "\n",
    "TN (il metodo dice che la persona non è contagiosa ed effettivamente non lo è): 990\n",
    "\n",
    "FN (il metodo dice che la persona non è contagiosa ma in realtà lo è): 6\n",
    "\n",
    "FP (il metodo dice che la persona è contagiosa ma in realtà non lo è): 4\n",
    "\n",
    "Se calcoliamo l'accuratezza otteniamo:\n",
    "\n",
    "\\begin{equation*}\n",
    "accuracy = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{0 + 990}{0 + 990 + 4 + 6} = 0,99\n",
    "\\end{equation*}\n",
    "\n",
    "Verrebbe da dire che è un metodo ottimo, perché ha una accuratezza del 99%. In realtà è un metodo che trova molti __non__ contagiati ma non trova neanche __un__ contagiato effettivo (TP = 0), che era invece il motivo per cui abbiamo cercato di utilizzare i metodi del Machine Learning. Per questo motivo è utile calcolare metriche aggiuntive che raccolgano aspetti più specifici della valutazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__precision: what proportion of positive identifications was actually correct?__<br><br>\n",
    "è la percentuale di classificazioni positive corrette, cioè i positivi effettivi (true label = 1, predicted label = 1 ossia TP) rispetto a tutti quelli che il metodo ha classificato come positivi, sia correttamente (true label = 1, predicted label = 1 ossia TP) sia non correttamente (true label = 1, predicted label = 1 ossia FP). In formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "precision = \\frac{TP}{TP + FP} \n",
    "\\end{equation*}\n",
    "\n",
    "Nel nostro caso è il rapporto tra il numero dei pazienti che il modello ha predetto essere diabetici (true label = 1, predicted label = 1) rispetto tutti quelli diagnosticati dal modello come diabetici (in modo corretto e no, predicted label = 1)<br>Vediamo il calcolo:\n",
    "\n",
    "\\begin{equation*}\n",
    "precision = \\frac{TP}{TP + FP} = \\frac{50}{50 + 42} = 0,5435\n",
    "\\end{equation*}\n",
    "\n",
    "Questo vuol dire che il __54%__ di chi è stato diagnosticato (classificato) dal metodo come diabetico lo era effettivamente. La _precision_ è massima quando non ci sono falsi positivi, cioè, nel nostro caso, quando non ci sono pazienti a cui è stato diagnosticato il diabete ma che in realtà non erano diabetici.\n",
    "\n",
    "Calcoliamo ora la _precision_ per l'esempio del Coronavirus:\n",
    "\n",
    "\\begin{equation*}\n",
    "precision = \\frac{TP}{TP + FP} = \\frac{0}{0 + 4} = 0\n",
    "\\end{equation*}\n",
    "\n",
    "Questo risultato ci conferma quanto sapevamo già: questo metodo non è per niente utile nel caso dei contagi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__recall: what proportion of actual positives was identified correctly?__\n",
    "\n",
    "è la percentuale di veri positivi identificati correttamente, cioè i veri positivi (true label = 1, predicted label = 1 cioè TP) rispetto a tutti quelli che erano effettivamente positivi nel dataset e che il metodo ha trovato (true label = 1, predicted label = 1 cioè TP) e non ha trovato (true label = 1, predicted label = 0 cioè FN). In formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "recall = \\frac{TP}{TP + FN} \n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Nel nostro caso è il rapporto tra il numero dei pazienti che il modello ha predetto essere diabetici (true label = 1, predicted label = 1) rispetto tutti quelli effettivamente diabetici (true label = 1).<br>Vediamo il calcolo:<br>\n",
    "\\begin{equation*}\n",
    "recall = \\frac{TP}{TP + FN} = \\frac{50}{50 + 39} = 0,5618\n",
    "\\end{equation*}\n",
    "\n",
    "Questo vuol dire che il __56%__ dei diabetici presenti nel dataset è stato correttamente identificato (classificato). La _recall_ è massima quando non ci sono falsi negativi, pazienti cioè a cui non è stato diagnosticato il diabete ma che invece erano diabetici.\n",
    "\n",
    "Calcoliamo ora la recall per l'esempio del Coronavirus:\n",
    "\n",
    "\\begin{equation*}\n",
    "precision = \\frac{TP}{TP + FP} = \\frac{0}{0 + 6} = 0\n",
    "\\end{equation*}\n",
    "\n",
    "Questo risultato rafforza quanto sapevamo già: questo metodo non è per niente utile nel caso dei contagi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__f1-score: un indicatore riassuntivo__\n",
    "\n",
    "A questo punto possiamo introdurre un indicatore riassuntivo di _precision_ e _recall_ che serve per dare un'indicazione di quanto il nostro metodo sia valido: l'___f1-score___\n",
    "\n",
    "\\begin{equation*}\n",
    "f1-score = 2*\\frac{precision*recall}{precision + recall}\n",
    "\\end{equation*}\n",
    "\n",
    "Questo indicatore è la media armonica di _precision_ e _recall_ e serve per tenere conto dei falsi positivi e dei falsi negativi nella valutazione di un metodo, evitando di considerare i veri negativi. Infatti l'accuratezza può essere molto influenzata da un numero elevato di veri negativi (TN) che nella maggior parte delle applicazioni reali non sono rilevanti (ad esempio non sono particoalrmente interessato a sapere se un paziente non è diabetico), mentre i falsi negativi e i falsi positivi di solito sono importanti (pensate al caso di un diabetico che non viene curato (FN) o al caso di sottoporre a cure costose un paziente che non è diabetico (FP)).\n",
    "\n",
    "_f1-score_ è quindi un misura migliore da usare (rispetto l'_accuracy_) se dobbiamo cercare un equilibrio tra _precision_ e _recall_ nel caso in cui ci sia un numero di TP, TN, FP o FN irregolare.\n",
    "\n",
    "Notare che _f1-score_ è massimo quando _precision_ e _recall_ sono uguali a 1 (cioè quando i falsi negativi e i falsi positivi sono uguali a 0), come si può vedere dal grafico seguente ( _p_ = _precision_ , _r_ = _recall_ ): \n",
    "\n",
    "<img src=\"Images/3d.png\" width=\"300\" align=\"center\"><br>\n",
    "\n",
    "Proviamo ora a calcolare l'_f1-score_ per il nostro caso:\n",
    "\n",
    "\\begin{equation*}\n",
    "f1-score = 2*\\frac{precision*recall}{precision + recall} = 2*\\frac{0,5435*0,5618}{0,5435 + 0,5618} = 0,5525\n",
    "\\end{equation*}\n",
    "\n",
    "Il nostro metodo non si comporta quindi particolarmente bene, visto che l'_f1-score_ massimo è 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso che abbiamo capito i vari indicatori, stampiamo il report dei vari indicatori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.75      0.75       165\n",
      "         1.0       0.54      0.56      0.55        89\n",
      "\n",
      "    accuracy                           0.68       254\n",
      "   macro avg       0.65      0.65      0.65       254\n",
      "weighted avg       0.68      0.68      0.68       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere, abbiamo ritrovato i valori precedentemente calcolati per l'_accuracy_ , la _precision_ e la _recall_ (per i pazienti diabetici, target = 1.0). Notare che gli stessi indicatori (tranne l'_accuracy_ che è complessiva) si possono calcolare anche per l'altro caso, cioè per i __non__ diabetici: dalla comparazione dei risultati vediamo che il metodo funziona meglio se dobbiamo trovare chi __non__ è diabetico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizzare il metodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al di là dei risultati che ci hanno dato i nostri indicatori, supponiamo che il nostro metodo sia un ottimo metodo per valutare (classificare) se una persona è diabetica o no: come fa un medico  ad applicarlo ai dati di un paziente che gli arriva nello studio? Supponiamo per esempio che Maria abbia la seguente situazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  timespreg    gluctol    diaspb    triceps    insulin    massindex    pedigree    age\n",
      "-----------  ---------  --------  ---------  ---------  -----------  ----------  -----\n",
      "         10         68       106         23         49         35.5       0.285     47\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "info = ['timespreg', 'gluctol', 'diaspb', 'triceps', 'insulin', 'massindex', 'pedigree', 'age'] # nome delle misurazioni\n",
    "Maria= [10., 68., 106., 23., 49., 35.5, 0.285, 47.] # valore delle misurazioni\n",
    "print(tabulate([Maria], headers=info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo a far girare il nostro metodo con questi dati e vediamo che cosa ci dice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previsione per Maria\n",
    "Maria = [[10., 68., 106., 23., 49., 35.5, 0.285, 47.]]\n",
    "predictMaria = neigh.predict(Maria)\n",
    "predictMaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La risposta è 0, cioà il metodo dice che Maria non ha il diabete (cioè, visto che stiamo usando il metodo K-NN, Maria è più 'vicina' a pazienti che non hanno il diabete). Ma vediamo ora che cosa sarebbe successo se Maria avesse un indice relativo all'insulina di 159 invece che 49:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nuova previsione per Maria\n",
    "Maria = [[10., 68., 106., 23., 159., 35.5, 0.285, 47.]]\n",
    "predictMaria = neigh.predict(Maria)\n",
    "predictMaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La risposta è 1, cioè il metodo dice che Maria, con questi nuovi valori, ha il diabete (cioè è più 'vicina' a pazienti che hanno il diabete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k(training_set_X, training_set_y, testing_set_X, testing_set_y, max_k=11):\n",
    "    y = [0,0]\n",
    "    for i in range(1,int(max_k)+1,2):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "        neigh.fit(training_set_X, training_set_y)\n",
    "        predict_knn = neigh.predict(testing_set_X)\n",
    "        x = [i, float(classification_report(testing_set_y, predict_knn, output_dict=True).get(\"accuracy\"))]\n",
    "        if (x[1] > y[1]):\n",
    "            y = x\n",
    "        else:\n",
    "            pass\n",
    "    print(f'{y[0]} => {y[1]}')\n",
    "find_k(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 => 0.7559055118110236\n"
     ]
    }
   ],
   "source": [
    "find_k(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
